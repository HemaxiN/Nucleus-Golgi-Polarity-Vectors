{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374070c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from typing import List, Dict, Tuple\n",
    "import io\n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "import datetime\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.transforms\n",
    "import torch_geometric.datasets\n",
    "import torch_geometric.nn\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_variables import *\n",
    "from utils_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f73a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_output_dir = \"./results\"\n",
    "if not os.path.exists(results_output_dir):\n",
    "    os.makedirs(results_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd99e9a",
   "metadata": {},
   "source": [
    "# Bipartite Matching Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_params_bipartite(debug = False):\n",
    "    data_types = [\n",
    "                    #\"Synthetic_random_walk_2D_z_normal_distribution\",\n",
    "                    #\"Synthetic_lin_1D_y_random_walk_z_fixed\",\n",
    "                    #\"Synthetic_lin_1D_y_fixed_z_fixed\",\n",
    "                    \"Real_automatic\",\n",
    "                    \"Real\"\n",
    "    ]\n",
    "\n",
    "    combinations = {\n",
    "        \"data_type_train\": data_types,\n",
    "        \"model_type\":[\n",
    "                        #\"Hopcroft_Karp\",\n",
    "                        \"Minimum Weight\"\n",
    "        ],\n",
    "        \"knn_inter_nodes\":[\n",
    "                            #\"min\",\n",
    "                            #7,\n",
    "                            10\n",
    "        ],\n",
    "        \"knn_inter_nodes_max\": [7],\n",
    "       \"knn_intra_nodes\":[0],\n",
    "        \"normalize\":[True, False],\n",
    "        \"node_feats\":[[\n",
    "            'Y', \n",
    "            'X', \n",
    "            'Z', \n",
    "            'node_type', \n",
    "            'ID'\n",
    "        ]],\n",
    "        \"edge_feats\":[[\n",
    "    'source',\n",
    "    'target',\n",
    "     'edge_label',\n",
    "     'delta_x',\n",
    "     'delta_y',\n",
    "     'delta_z',\n",
    "     'weight',\n",
    "     'edge_type',\n",
    "     'angle_orientation_theta',\n",
    "     'angle_orientation_phi']],\n",
    "    }\n",
    "\n",
    "\n",
    "    job_parameters = []\n",
    "\n",
    "\n",
    "    # Generate all possible combinations of the dictionary values\n",
    "    for values in itertools.product(*combinations.values()):\n",
    "        # Generate a dictionary for the combination of values\n",
    "        job_dict = dict(zip(combinations.keys(), values))\n",
    "        job_dict[\"scale_features\"] = True if \"Real\" in job_dict[\"data_type_train\"] else False\n",
    "        job_parameters.append(job_dict)\n",
    "    \n",
    "    if(debug):\n",
    "        print(\"Total Number of jobs is:\",len(job_parameters))\n",
    "        print(json.dumps(job_parameters, indent = 1))\n",
    "    return job_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4741f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_list_bipartite(job_parameters, debug = False):\n",
    "    #build dataframes\n",
    "    graph_list_dict_bipartite = {}\n",
    "\n",
    "    for params in tqdm(job_parameters):\n",
    "\n",
    "        params_list = [params[\"data_type_train\"], params[\"knn_inter_nodes\"], params[\"knn_intra_nodes\"], \n",
    "                                        params[\"knn_inter_nodes_max\"],params[\"normalize\"],\n",
    "                                        params[\"scale_features\"], str(params[\"node_feats\"]), str(params[\"edge_feats\"])]\n",
    "        params_list = [str(param_) for param_ in params_list]\n",
    "        graph_key = \"_\".join(params_list)\n",
    "\n",
    "        if graph_key not in graph_list_dict_bipartite:\n",
    "            graph_list = get_graph_list(params[\"data_type_train\"], params[\"knn_inter_nodes\"], params[\"knn_intra_nodes\"], \n",
    "                                            params[\"knn_inter_nodes_max\"], normalize = params[\"normalize\"],\n",
    "                                            scale_feats = params[\"scale_features\"],\n",
    "                                            node_feats = params[\"node_feats\"], edge_feats = params[\"edge_feats\"],\n",
    "                                            shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "            graph_list_dict_bipartite[graph_key] = graph_list\n",
    "\n",
    "        graph_list_instance = list(graph_list_dict_bipartite.values())[0]\n",
    "        graph_instance = graph_list_instance[0]\n",
    "        graph_instance_properties = vars(graph_instance).keys()\n",
    "        if(debug):\n",
    "            print(graph_instance_properties)\n",
    "            \n",
    "            print(graph_instance.pyg_graph)\n",
    "\n",
    "            display(graph_instance.nodes_df)\n",
    "            \n",
    "            display(graph_instance.edges_df_knn)\n",
    "            \n",
    "            print(graph_instance.pyg_graph.x)\n",
    "\n",
    "            print(graph_instance.pyg_graph.edge_attr)\n",
    "\n",
    "    return graph_list_dict_bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bipartite(graph_list_dict_bipartite, job_parameters, debug = False, make_plots = True):\n",
    "    results_list_mf = []\n",
    "\n",
    "    for params in job_parameters:\n",
    "        print(\"\\n\\n\\n####################################\")\n",
    "        metrics_list_bipartite = []\n",
    "\n",
    "        params_list = [params[\"data_type_train\"], params[\"knn_inter_nodes\"], params[\"knn_intra_nodes\"], \n",
    "                                        params[\"knn_inter_nodes_max\"],params[\"normalize\"],\n",
    "                                        params[\"scale_features\"], str(params[\"node_feats\"]), str(params[\"edge_feats\"])]\n",
    "        params_list = [str(param_) for param_ in params_list]\n",
    "        graph_key = \"_\".join(params_list)\n",
    "        graph_list = graph_list_dict_bipartite[graph_key]\n",
    "\n",
    "        for graph in graph_list:\n",
    "            graph_id, nodes_df, edges_df, edges_df_knn, k_intra, k_inter = graph.graph_id, graph.nodes_df, graph.edges_df, graph.edges_df_knn, graph.k_intra, graph.k_inter\n",
    "            print(\"Graph_ID:\",graph_id,\"K_INTRA:\",k_intra, \"K_INTER:\",k_inter)\n",
    "\n",
    "            edges_df_bipartite_graph = edges_df_knn.copy()\n",
    "            nx_G_knn = nx_build_graph(nodes_df, edges_df_bipartite_graph)\n",
    "\n",
    "            model_type = params[\"model_type\"]\n",
    "\n",
    "            #get the bipartite edges_list\n",
    "            if(model_type==\"Hopcroft_Karp\"):\n",
    "                nx_bipartite_edges_list = nx.bipartite.maximum_matching(nx_G_knn)\n",
    "            elif(model_type==\"Eppstein\"):\n",
    "                nx_bipartite_edges_list = nx.bipartite.eppstein_matching(nx_G_knn)\n",
    "            elif(model_type==\"Minimum Weight\"):\n",
    "                nx_bipartite_edges_list = nx.bipartite.minimum_weight_full_matching(nx_G_knn)\n",
    "            else:\n",
    "                raise ValueError(\"Model not implemented!\")\n",
    "\n",
    "            #convert to Dataframe\n",
    "            edges_df_bipartite = nx_convert_dict_to_edges_df(nx_bipartite_edges_list)\n",
    "            #apply the pred labels to edges_df_bipartite, taking as input the edges_df_knn\n",
    "            edges_df_bipartite[\"edge_label\"] = 1\n",
    "            edges_df_bipartite = apply_edges_df_label(edges_df_bipartite, edges_df_knn)\n",
    "\n",
    "            metrics_bipartite, edge_labels_string_bipartite = eval_edges_df(edges_df, edges_df_bipartite)\n",
    "            metrics_list_bipartite.append(metrics_bipartite)\n",
    "\n",
    "            print(json.dumps(metrics_bipartite, indent = 1))\n",
    "\n",
    "            #Save results to file\n",
    "            bipartite_results_array = pred_df_to_csv(edges_df_bipartite, graph.nodes_df_original)\n",
    "            output_file_dir =  results_output_dir+\"/\"+params[\"data_type_train\"]+\"_\"+params[\"model_type\"]+\"_\" +\\\n",
    "                                    str(params[\"knn_inter_nodes\"])+\"_\"+str(params[\"knn_intra_nodes\"])+\"/\"\n",
    "            if not os.path.exists(output_file_dir):\n",
    "                os.makedirs(output_file_dir)\n",
    "            output_file_path = os.path.join(output_file_dir, graph.graph_id)\n",
    "            array_to_csv(bipartite_results_array, output_file_path)\n",
    "\n",
    "            if(make_plots):\n",
    "                fig_bipartite = df_make_plot(nodes_df, edges_df_bipartite, edge_labels_string_bipartite, \"Bipartite\")\n",
    "                plt.show()\n",
    "\n",
    "        ####################################\n",
    "        ### Aggregate Metrics at the end  ##\n",
    "        ####################################\n",
    "\n",
    "        metrics_bipartite_aggregated = aggregate_metrics(metrics_list_bipartite)\n",
    "        print(json.dumps(metrics_bipartite_aggregated,indent = 1))\n",
    "\n",
    "        result_bipartite = {}\n",
    "        result_bipartite[\"aggregated_metrics\"] = metrics_bipartite_aggregated\n",
    "        params[\"angle_features\"] = \"NA\"\n",
    "        params[\"constraints\"] = \"NA\"\n",
    "        result_bipartite[\"job_parameters\"] = params\n",
    "        results_list_mf.append(result_bipartite)\n",
    "    return results_list_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19088fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_bipartite(results_list_bipartite):\n",
    "    plot_df_mf = plot_table(results_list_bipartite, metrics_dict_entries = [None])\n",
    "    plot_df_mf = plot_df_mf.sort_values(by=[\"K Inter\", 'Algorithm', 'Data Train', 'Data Test'])\n",
    "    display(plot_df_mf)\n",
    "    plot_df_mf = plot_df_mf.drop([\"Data Train\", \"Data Test\", \"Scale\"], axis=1)\n",
    "    display(plot_df_mf)\n",
    "    print(plot_df_to_latex(plot_df_mf))\n",
    "    return plot_df_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c93120",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_parameters_bipartite = get_job_params_bipartite(debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list_dict_bipartite = get_graph_list_bipartite(job_parameters_bipartite, debug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66444ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_bipartite = train_bipartite(graph_list_dict_bipartite, job_parameters_bipartite, debug = True, make_plots = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ab348",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_bipartite(results_list_bipartite) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722b404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
